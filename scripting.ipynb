{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "config = edict()\n",
    "\n",
    "# training parameters\n",
    "config.batch_size = 64#32\n",
    "config.patch_size = 100\n",
    "config.mode = \"RGB\"\n",
    "config.channels = 3\n",
    "config.content_layer = 'relu2_2' # originally relu5_4 in DPED\n",
    "config.learning_rate = 1e-4\n",
    "config.augmentation = True #data augmentation (flip, rotation)\n",
    "config.test_every = 200\n",
    "config.train_iter = 50000\n",
    "config.data_loader_workers = 16\n",
    "config.pin_memory = 2\n",
    "# config.sample_size = 100000\n",
    "\n",
    "# weights for loss\n",
    "config.w_content = 2 # reconstruction (originally 1)\n",
    "config.w_profile = 0.2\n",
    "config.w_color = 5 # gan color (originally 5e-3)\n",
    "config.w_texture = 2 # gan texture (originally 5e-3)\n",
    "config.w_tv = 3 # total variation (originally 400)\n",
    "config.gamma = 0.6\n",
    "config.model_name = \"WESPE_DIV2K_arnav_gpu1\"\n",
    "\n",
    "# directories\n",
    "config.dataset_name = \"iphone\"\n",
    "config.train_path_phone = os.path.join(\"/home/grads/v/vineet/Downloads/DPED/dped/iphone/training_data/iphone\",\"*.jpg\")\n",
    "config.train_path_canon = os.path.join(\"/home/grads/v/vineet/Downloads/DPED/dped/iphone/training_data/canon\",\"*.jpg\")\n",
    "config.train_path_DIV2K = os.path.join(\"/home/grads/v/vineet/Downloads/DPED/DIV2K_train_HR\",\"*.png\")\n",
    "\n",
    "config.test_path_phone_patch = os.path.join(\"/home/grads/v/vineet/Downloads/DPED/sample_images/original_images/iphone\",\"*.jpg\")\n",
    "config.test_path_phone_image = os.path.join(\"/home/grads/v/vineet/Downloads/DPED/sample_images/original_images/iphone\",\"*.jpg\")\n",
    "\n",
    "config.vgg_dir = \"./vgg_pretrained/imagenet-vgg-verydeep-19.mat\"\n",
    "\n",
    "config.result_dir = os.path.join(\"./result_1\", config.model_name)\n",
    "config.result_img_dir = os.path.join(config.result_dir, \"samples\")\n",
    "config.checkpoint_dir = os.path.join(config.result_dir, \"model\")\n",
    "\n",
    "if not os.path.exists(config.result_dir):\n",
    "    print(\"creating dir...\", config.result_dir)\n",
    "    os.makedirs(config.result_dir)\n",
    "    \n",
    "if not os.path.exists(config.checkpoint_dir):\n",
    "    print(\"creating dir...\", config.checkpoint_dir)\n",
    "    os.makedirs(config.checkpoint_dir)\n",
    "\n",
    "if not os.path.exists(config.result_img_dir):\n",
    "    print(\"creating dir...\", config.result_img_dir)\n",
    "    os.makedirs(config.result_img_dir)\n",
    "    \n",
    "config.sample_dir = \"samples_DIV2K\"\n",
    "if not os.path.exists(config.sample_dir):\n",
    "    print(\"creating dir...\", config.sample_dir)\n",
    "    os.makedirs(config.sample_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: iphone, 160471 images\n",
      "DIV2K: 800 images\n",
      "160471 images loaded! setting took: 0.0952s\n"
     ]
    }
   ],
   "source": [
    "from dataloader.dataloader_torch import Dataset, get_patch\n",
    "from ops_torch import preprocess, postprocess\n",
    "import imageio\n",
    "from utils import calc_PSNR\n",
    "\n",
    "dataset = Dataset(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from generator import Generator\n",
    "from discriminator import Discriminator\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from vgg19_torch import net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                       batch_size=4,\n",
    "                                       shuffle=True,\n",
    "                                       num_workers=config.data_loader_workers,\n",
    "                                       pin_memory=config.pin_memory,\n",
    "                                       drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg_dir = config.vgg_dir\n",
    "content_layer = config.content_layer\n",
    "\n",
    "w_content = config.w_content\n",
    "w_profile = config.w_profile\n",
    "w_texture = config.w_texture \n",
    "w_color = config.w_color\n",
    "w_tv = config.w_tv\n",
    "gamma = config.gamma\n",
    "\n",
    "# Networks\n",
    "generator = Generator()\n",
    "discriminator1 = Discriminator(in_channels=3)\n",
    "discriminator2 = Discriminator(in_channels=3)\n",
    "discriminator3 = Discriminator(in_channels=1)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    generator, discriminator1, discriminator2, discriminator3 = \\\n",
    "    generator.cuda(), discriminator1.cuda(), discriminator2.cuda(), discriminator3.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn_D = nn.BCEWithLogitsLoss()\n",
    "optimizer_G = torch.optim.Adam(generator.parameters())\n",
    "optimizer_D1 = torch.optim.Adam(discriminator1.parameters())\n",
    "optimizer_D2 = torch.optim.Adam(discriminator2.parameters())\n",
    "optimizer_D3 = torch.optim.Adam(discriminator3.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_discriminator_unit(generated_patch, actual_batch, index, preprocess):\n",
    "\n",
    "    if index == 1:\n",
    "        act, _ = discriminator1(actual_batch, preprocess = preprocess)\n",
    "        fake, _ = discriminator1(generated_patch.detach(), preprocess = preprocess)\n",
    "\n",
    "    elif index == 2:\n",
    "        act, _ = discriminator2(actual_batch, preprocess = preprocess)\n",
    "        fake, _ = discriminator2(generated_patch.detach(), preprocess = preprocess)\n",
    "\n",
    "    elif index == 3:\n",
    "        act, _ = discriminator3(actual_batch, preprocess = preprocess)\n",
    "        fake, _ = discriminator3(generated_patch.detach(), preprocess = preprocess)\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    loss_real = loss_fn_D(act, torch.ones_like(act))\n",
    "    loss_fake = loss_fn_D(fake, torch.zeros_like(fake))\n",
    "    total_loss = loss_real+loss_fake\n",
    "\n",
    "    return total_loss, act, fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for step, (phone_patch, canon_patch, DIV2K_patch) in enumerate(data_loader):\n",
    "    break\n",
    "\n",
    "phone_patch, canon_patch, DIV2K_patch = phone_patch.float(), canon_patch.float(), DIV2K_patch.float()\n",
    "if torch.cuda.is_available():\n",
    "    phone_patch, canon_patch, DIV2K_patch = phone_patch.cuda(), canon_patch.cuda(), DIV2K_patch.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator-color (blur)\n",
      "Discriminator-color (blur)\n",
      "Discriminator-color (none)\n",
      "Discriminator-color (none)\n",
      "Discriminator-texture\n",
      "Discriminator-texture\n"
     ]
    }
   ],
   "source": [
    "enhanced_patch = generator(phone_patch)\n",
    "\n",
    "# Discrimiator 1\n",
    "d_loss_profile, logits_DIV2K_profile, logits_enhanced_profile = build_discriminator_unit(enhanced_patch, DIV2K_patch, index=1, preprocess='blur')\n",
    "\n",
    "# Discrimiator 2\n",
    "d_loss_color, logits_original_color, logits_enhanced_color = build_discriminator_unit(enhanced_patch, canon_patch, index=2, preprocess='none')\n",
    "\n",
    "# Discrimiator 3\n",
    "d_loss_texture, logits_original_texture, logits_enhanced_texture = build_discriminator_unit(enhanced_patch, canon_patch, index=3, preprocess='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def total_variation_loss(images):\n",
    "\n",
    "    ndims = len(images.shape)\n",
    "\n",
    "    if ndims == 3:\n",
    "        pixel_dif1 = images[:, 1:, :] - images[:, :-1, :]\n",
    "        pixel_dif2 = images[:, :, 1:] - images[:, :, :-1]\n",
    "        sum_axis = None\n",
    "\n",
    "    if ndims == 4:\n",
    "        pixel_dif1 = images[:, :, 1:, :] - images[:, :, :-1, :]\n",
    "        pixel_dif2 = images[:, :, :, 1:] - images[:, :, :, :-1]\n",
    "        sum_axis = (1, 2, 3)\n",
    "\n",
    "    else:\n",
    "        raise ValueError('\\'images\\' must be either 3 or 4-dimensional.')\n",
    "\n",
    "    tot_var = (\n",
    "        torch.sum(torch.abs(pixel_dif1)) +\n",
    "        torch.sum(torch.abs(pixel_dif2), dim=sum_axis))\n",
    "\n",
    "    return tot_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_vgg = net(vgg_dir, canon_patch * 255)\n",
    "enhanced_vgg = net(vgg_dir, enhanced_patch * 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "content_loss = torch.mean(torch.pow(original_vgg[content_layer] - enhanced_vgg[content_layer], 2))\n",
    "\n",
    "#profile loss(gan, enhanced-div2k)\n",
    "profile_loss = loss_fn_D(logits_DIV2K_profile, logits_enhanced_profile)\n",
    "\n",
    "# color loss (gan, enhanced-original)\n",
    "color_loss = loss_fn_D(logits_original_color, logits_enhanced_color)\n",
    "\n",
    "# texture loss (gan, enhanced-original)\n",
    "texture_loss = loss_fn_D(logits_original_texture, logits_enhanced_texture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_loss = torch.mean(torch.abs(total_variation_loss(enhanced_patch) - total_variation_loss(canon_patch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_loss = w_content*content_loss + w_profile*profile_loss + w_color*color_loss + w_texture*texture_loss + w_tv*tv_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_G.zero_grad()\n",
    "\n",
    "g_loss.backward(retain_graph=True)\n",
    "optimizer_G.step()\n",
    "\n",
    "optimizer_D1.zero_grad()\n",
    "optimizer_D2.zero_grad()\n",
    "optimizer_D3.zero_grad()\n",
    "\n",
    "d_loss_profile.backward()\n",
    "optimizer_D1.step()\n",
    "\n",
    "d_loss_color.backward()\n",
    "optimizer_D2.step()\n",
    "\n",
    "d_loss_texture.backward()\n",
    "optimizer_D3.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generator.eval()\n",
    "discriminator1.eval()\n",
    "discriminator2.eval()\n",
    "discriminator3.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "import scipy.io\n",
    "\n",
    "config.test_path_phone_patch = '/home/grads/v/vineet/Downloads/DPED/DIV2K_train_HR/*.png'\n",
    "test_list_phone = sorted(glob(config.test_path_phone_patch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_num_patch = 200\n",
    "test_num_image = 5\n",
    "PSNR_phone_enhanced_list = np.zeros([test_num_patch])\n",
    "\n",
    "indexes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(test_num_patch):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grads/v/vineet/.conda/envs/DL/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "index = np.random.randint(len(test_list_phone))\n",
    "indexes.append(index)\n",
    "test_img = scipy.misc.imread(test_list_phone[index], mode = \"RGB\").astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_patch_phone = get_patch(test_img, config.patch_size)\n",
    "test_patch_phone = preprocess(test_patch_phone)\n",
    "\n",
    "test_patch_phone = torch.from_numpy(np.transpose(test_patch_phone, (2,1,0))).float().unsqueeze(0).cuda()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    test_patch_phone = test_patch_phone.cuda()\n",
    "\n",
    "test_patch_enhanced = generator(test_patch_phone)\n",
    "test_patch_enhanced = np.transpose(test_patch_enhanced.cpu().data.numpy(), (0,2,3,1))\n",
    "test_patch_phone = np.transpose(test_patch_phone.cpu().data.numpy(), (0,2,3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "PSNR = calc_PSNR(postprocess(test_patch_enhanced[0]), postprocess(test_patch_phone[0]))\n",
    "PSNR_phone_enhanced_list[i] = PSNR"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
